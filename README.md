# learning-RAG-application
This repo is for me to learn more about RAG application

# What is RAG (Retrieval Augmented Generation) ?

**RAG**, is a technique to **enhance** the **quality of responses** generated by a *large language model* (LLM), by **augmenting its pre-trained knowledge with information retrieved from external sources**. This results is more accurate responses from the LLM by **grounding them in real, contextually relevant data**. 

- Basic concept: RAG **augments language models** with **external knowledge retrieved from a large corpus**.
- Components: It typically involves a retriever to find relevant information and a generator to produce text based on the retrieved content and input query.
- Advantages: RAG can *improve* **accuracy**, *reduce* **hallucinations**, and allow models to **access up-to-date information**.
- Applications: It's used in question answering, chatbots, content generation, and more.

# When to use RAG ?
RAG is best suited for the following:
- Tasks that **require very specific information** that you don't think will be present in the LLMs parametic knowledge, i.e. **information that is not widely available on the internet**
- Tasks that **require information** from **multiple different data sources**
- Tasks that involve **basic question-answering** or **summarization on a piece of information**

However, RAG is **not ideal** for tasks that require **complex multi-step reasoning**, **long-term planning**, or **deep deductive logic**. These tasks require more **sophisticated decision-making capabilities**, which are **better handled by agentic workflows**.

In simpler terms, RAG **excels** at **finding** and **synthesizing** information quickly but may **struggle** with tasks that require **continuous**, **adaptive reasoning over many steps**. Agentic workflows, which involve more dynamic and autonomous systems, are better suited for handling these more intricate tasks.

# Here are some examples of tasks/questions that DO NOT require or cannot be achieved with RAG:

> Who was the first president of the United States?

The information required to answer this question is very likely present in the parametric knowledge of most LLMs. Hence, this question can be answered using a simple prompt to an LLM.

> How has the trend in the average daily calorie intake among adults changed over the last decade in the United States, and what impact might this have on obesity rates? Additionally, can you provide a graphical representation of the trend in obesity rates over this period?

This question involves multiple sub-tasks such as data aggregation, visualization, and reasoning. Hence, this is a good use case for an AI agent rather than RAG.

Here are some use cases for RAG:

> What is the travel reimbursement policy for meals for my company?

The information required to answer this question is most likely not present in the parametric knowledge of available LLMs. However, this question can easily be answered using RAG on a knowledge base consisting of your company's data.

> Hi, I'm having trouble installing your software on my Windows 10 computer. It keeps giving me an error message saying 'Installation failed: Error code 1234'. How can I resolve this issue?

Again, this question requires troubleshooting information for a specific software, the documentation for which might not be widely available, but can be solved using RAG.

# High Level Architetcure of 

# Components of a RAG system
RAG systems have two main components: Retrieval and Generation.

## Retrieval
Retrieval mainly involves processing your data and constructing a knowledge base in a way that you are able to efficiently retrieve relevant information from it. It typically involves three main steps:

Chunking: Break down large pieces of information into smaller segments or chunks.

Embedding: Convert a piece of information such as text, images, audio, video, etc. into an array of numbers a.k.a. vectors.

Semantic Search: Retrieve the most relevant documents from the knowledge base based on embedding similarity with the query vector.

## Generation
Generation involves crafting a prompt that contains all the instructions and information required by the LLM to generate accurate answers to user queries.